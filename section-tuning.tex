%Section Balancing Completeness and Reliability
\label{s:optimize}
As described in the previous section, the Robovetter makes decisions regarding which TCEs are FPs and PCs based on a collection of metrics and thresholds.  For each metric we apply a threshold and if the TCE's metrics' values lies above (or below, depending on the metric) the threshold then the TCE is called a FP.  Ideally the Robovetter thresholds would be tuned so that no true PCs are lost and all of the known FPs are removed; however, this is not a realistic goal.  Instead we sacrifice a few \injtce{s} in order to improve our measured reliability. 

We used automated methods to search for those thresholds that passed the most \injtce{s} and failed the most \invtce{s} and \scrtce{s}. We only used the thresholds found from this automated optimization to inform how to chose the final set of thresholds. This is because the simulated TCEs do not entirely emulate the observed data and many of the metrics have a period and MES dependence.  For example, the injections were heavily weighted towards long periods and low MES so our automated code sacrificed many of the short period candidates in order to keep more of the long period 
\injtce{s}. 

%many of the metrics have a period and MES dependencewe found that because of the period and MES dependence of the various metrics, the prevalence of different types of lse alarms in different parts of parameter space, and the inability of the simulated TCE sets to perfectly emulate the data sets , 


%No metric is perfect. The metrics we use in the Robovetter are those that were identified to remove a significant number of FPs while only throwing away a small number of PCs.  However, some metrics work on small populations 
%As a result the set of potential thresholds to use is infinite and there is no perfect way to tune the Robovetter.
%We tuned the Robovetter by measuring the reliability and completeness measured from these simulated data sets. 

\subsection{Setting Metric Thresholds Through Optimization}
\label{s:full_optimize}
For the first step in Robovetter tuning, we perform an optimization that finds the metric thresholds that maximize the fraction of TCEs from the \injtce\ set that are classified as PCs (i.e., completeness) and minimizes the fraction of TCEs from the \scrtce\ and \invtce\ sets identified as PCs (minimizes ineffectiveness or $1-E$.) Optimization varies the thresholds of the subset of Robovetter metrics described below, looking for those thresholds that maximize completeness and minimize ineffectiveness.

%We define the {\it true positive fraction} (TPF) as the ratio of the number of \injtce\  classified as PC to the total number of \injtce\ (this is a measure of the catalog completeness, $C$), and the {\it false positive fraction} (FPF) as the number of TCEs from the \scrtce\ and \invtce\ sets identified as PCs to the total number of \scrtce\ and \invtce\ TCEs (this is a measure of ineffectiveness or one minus the effectiveness $1-E$).  

This optimization is performed jointly across a subset of the metrics described in \S\ref{s:robovetter}.  Metrics chosen for this joint optimization are either thought {\it a priori} to distinguish PCs from FPs or have distributions in the \injtce\ set that are statistically well-separated from those in the \scrtce\ and \invtce\ sets.  By ``well-separated" we mean that the distributions' medians are separated by more than 0.5 times the largest maximum absolute deviation of the \injtce, \scrtce\ or \invtce\ sets.  The set of metrics chosen for the joint optimization, called ``optimized metrics" are: LPP (\S\ref{s:lpp}), the model shift uniqueness test metrics ($MS_{1}$, $MS_{2}$, and $MS_{3}$, \S\ref{s:ms}), max SES to MES (\S\ref{s:sesmes}), and TCE Chases (\S\ref{s:tcechases}). Both the DV and ALT versions of these metrics, when applicable, were used in the optimization.  

Metrics not used in the joint optimization are incorporated by classifying TCEs as PCs or FPs using {\it a priori} thresholds for these non-optimized metrics prior to optimization of the optimized metrics.  After optimization, a TCE is classified as a PC only if it passes both the non-optimized metrics and the optimized metrics.  Prior to optimization the thresholds for these non-optimized metrics passed about 80\% of the  \injtce\ set, so the final optimized set can have at most 80\% completeness.  

Optimization is performed by varying the selected thresholds, determining which TCEs are classified as PCs by both the optimized and non-optimized metrics using the new optimized thresholds, and computing $C$ and $1-E$.  Our optimization seeks thresholds that minimize the objective function $\sqrt{{\rm 1-E}^2 + ({\rm C} - {\rm C}_0)^2}$, where ${\rm C}_0$ is the target completeness, so the optimization tries to get as close as possible to ${\rm 1-E} = 0$ and ${\rm C} = {\rm C}_0$.  We varied ${\rm C}_0$ in an effort to reduce the ineffectiveness. The thresholds are varied from random starting seed values, using the Nelder-Mead simplex algorithm via the \textsc{MATLAB} {\it fminsearch} function.  This \textsc{MATLAB} function varies the thresholds until the objective function is minimized.  There are many local minima, so the optimal thresholds depend sensitively on the random starting threshold values.  The optimal thresholds we report are the smallest of 2000 iterations with different random seed values.

Our final optimal threshold used a target of ${\rm C}_0 = 0.8$, which resulted in thresholds that yielded ${\rm 1-E} = 0.0044$ and ${\rm C} = 0.799$.  We experimented with smaller values of ${\rm C}_0$, but these did not significantly lower ineffectiveness.   We also performed an optimization that maximized reliability defined in \S\ref{s:relcalc} rather than minimizing ineffectiveness. This yielded similar results. 

We explored using only one of \scrtce\ or \invtce\ to determine the ineffectiveness, and found that using both provided the best starting point for the final Robovetter thresholds described below.  We also explored the dependence of the optimal thresholds on the range of TCE MES and period.  We found that the thresholds have a moderate dependence, while the ineffectiveness and completeness have significant dependence on MES and period range.  For example, optimizing to the low-MES, long-period regime of long-period small-planet TCEs,  we find an ineffectiveness of 2.8\% and completeness of 73\%.  Exploration of this dependence of Robovetter threshold on MES and period range is a topic for future study.

\subsection{Picking the Final Robovetter Metric Thresholds}

The results of this algorithmic optimization were used as a starting point for the final thresholds chosen for the DR25 catalog. We used the Confirmed Planet table and the Certified False Positive Table at the Exoplanet Archive, as well as the results of some prominent KOIs,  to adjust the thresholds.  Because most of the \injtce{s}, \invtce{s} and \scrtce{s} are at long periods and low MES the automated tuning optimized the completeness and effectiveness for this part of the catalog. However, many of \Kepler{'s} planet candidates are short period and high SNR. The final catalog thresholds balanced the needs of the different parts of the catalog and endeavoured to keep the completeness of the long period candidates above 70 per cent.

For those interested in a certain part of the KOI catalog, it may be better to re-tune to optimize for higher reliability or to more aggressively remove certain types of false alarms.   The Robovetter code\footnote{\url{https://github.com/nasa/kepler-robovetter}} (and the Robovetter input files) are provided with the tunable thresholds listed at the top of the code.  As an example, we include Table~\ref{t:thresholds} as a list of the easily tunable thresholds for the metrics that determine whether an object is not transit-like.  The table lists the thresholds we settled on for the DR25 catalog we present here, but it also provides the metrics for a higher reliability (lower completeness) catalog and a higher completeness (lower reliability) catalog. Each metric has its own range of possible values and some are more sensitive to small adjustments than others.  Users should use caution when changing the thresholds and should endeavour to understand the different metrics, described in \S\ref{s:robovetter} and Appendix\ref{s:metrics}, before doing so.


\input{Table-RV-thresh}

