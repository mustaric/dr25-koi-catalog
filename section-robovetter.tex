\label{s:robovetter}
The dispositioning of the TCEs into the categories of PC and FP is entirely automated and is performed by a piece of code called the Robovetter\footnote{GITHUB link}. This code uses a variety of metrics to evaluate the TCEs and disposition them into PCs and FPs.  

%In this section we describe the different metrics as well as the logic the Robovetter uses to make its decisions. 

Because the TCE population changed significantly between DR24 and DR25 (see Figure~\ref{f:obstces}), the Robovetter had to be improved in order to obtain an acceptable performance.  Also, because we now have simulated false alarms (\invtce\ and \scrtce) and true transits (\injtce), the Robovetter could be tuned to keep the most \injtce{s} (known as completeness) and remove the most \invtce{s} and \scrtce{s} (known as effectiveness). This is change from previous KOI catalogs that prioritized completeness above all else.  In order to sufficiently remove the long period excess of false alarms, this Robovetter introduces new metrics that evaluate individual transits. This expands the work that the code Marshall \citep{Mullally2015c} performed for the DR24 KOI catalog.

Because enough of the Robovetter tests and metrics changed between DR24 and DR25, we describe all of the metrics in full.  However, to not overwhelm the reader, we start by summarizing the important aspects of the Robovetter logic and provide a list of each test's purpose and have moved the details of these metrics to the \S\ref{s:metrics}. We close this section by explaining the creation of a ``disposition score'' that conveys the confidence in the Robovetter's disposition.


\subsection{Summary of the Robovetter}

\noindent In Figure~\ref{robovetter-overview-fig} we present a flowchart that outlines our robotic vetting procedure. Each TCE is subjected to a series of ``yes'' or ``no'' questions (represented by diamonds) that either disposition it into one or more of the four FP categories, or else disposition it as a PC. Behind each question is a series of more specific questions, each answered by quantitative tests. 


\begin{figure*}[ht]
\centering
\includegraphics[width=\linewidth]{RoboVetter-Diagram-V4-Overview.pdf}
\caption{Overview flowchart of the robovetter. Diamonds represent ``yes'' or ``no'' decisions that are made with quantitative metrics. A TCE is dispositioned as a FP if it fails any test (a ``yes'' decision) and is placed in one or more of the FP categories. If a TCE passes all tests (a ``no'' decision for all tests) it is dispositioned as a PC. The section numbers on each component correspond to the sections in this paper where these tests are discussed. ***UPDATE SECTION HEADERS WHEN PAPER IS NEAR FINAL***. More in-depth flowcharts are provided for the not transit-like and significant secondary modules in Figures~\ref{robovetter-transitlike-fig} and \ref{robovetter-sigsec-fig}.}
\label{robovetter-overview-fig}
\end{figure*}


The Robovetter first checks if the TCE corresponds to a secondary eclipse associated with an already examined system. If not, the Robovetter then checks if the TCE is transit-like or not. If it is transit-like, the Robovetter then looks for the presence of a secondary eclipse. In parallel, the Robovetter also looks for evidence of a centroid offset and an ephemeris match to other TCEs and variable stars in the \kepler{} field. 

\label{s:majorflags}
Similar to \citet{Rowe2015a}, \citep{Mullally2015cat}, and \citet{Coughlin2016}, the Robovetter assigns FP TCEs to one or more of the following false positive categories:


\begin{itemize}
  \item Not Transit-Like (NT): a TCE whose light curve is not consistent with that of a transiting planet or eclipsing binary, such as instrumental artifacts and non-eclipsing variable stars.
  \item  Stellar Eclipse (SS): a TCE that is observed to have a significant secondary event, transit shape, or out-of-eclipse variability that indicates the transit-like event is most likely caused by an eclipsing binary. (Self-luminous, hot Jupiters with a visible secondary eclipse are also in this category, but are still given a disposition of PC.)
  \item Centroid Offset (CO): a TCE whose signal is observed to originate on a nearby star, rather than the target star, based on examination of the pixel-level data.
  \item Ephemeris Match Indicates Contamination (EC): a TCE that has the same period and epoch as another object, and is not the true source of the signal given the relative magnitudes, locations, and signal amplitudes of the two objects.
\end{itemize}

The specific tests that caused the TCE to fail that category are given by a minor flag. These flags are described in \S\ref{s:minorflags}) and are available for all FPs.  Table~\ref{t:metrics} gives a summary of the specific tests run by the Robovetter when evaluating a TCE.  The table lists the false positive category the test belongs to and which minor flags it sets.  Note that there are several informative minor flags, which are listed in \S\ref{s:minorflags}, but are not listed in Table~\ref{t:metrics} because they do not cause TCEs to be come FPs.

New to this Robovetter are several tests that look at individual transits. The tests named after the code that calculates a metric and are called: Rubble, Marshall, Chases, Skye, Zuma and Tracker.  Each metric only identifies which transits can be considered ``bad", or not sufficiently transit-like.  The Robovetter then fails the TCE if the number of remaining good transits is not above three, or if the recalculated MES, using only the good transits, drops below 7.1.

Another note-worth change to the DR25 Robovetter is the introduction of the v-shape metric, originally used in \citet{Batalha2013}.  The intent is to remove likely eclipsing binaries which do not show significant secondary eclipses by looking at the shape of the transit, see \S\ref{s:shapemetric}.

\input{table-metrics}

\subsection{Disposition Scores}
\label{s:scores}
A new feature we introduce in this catalog is the disposition score --- a value between 0 and 1 that indicates the confidence in disposition provided by the Robovetter. A higher valued indicates more confidence that an objects is a PC, regardless of the disposition it was given.  This feature allows one to select the highest quality PCs by ranking KOIs by the disposition score. 
%This statistics argument hasn't been proven. We could discuss this, but it belongs in the disucssion "and weight them appropriately for their statistics."

The disposition score was calculated by wrapping the Robovetter in a Monte Carlo routine. In each of 10,000 iterations the input metrics for the Robovetter are perturbed from their nominal values by drawing from an asymmetric Gaussian distribution centered on the nominal value. In each iteration the robovetter dispositions each TCE given the new values for each metric. The disposition score is simply the fraction of iterations that result in a disposition of PC. For example, if a PC KOI has a few metrics that are near the Robovetter's thresholds, it will frequently have at least one that is perturbed across a threshold. As a result, many of the iterations will produce a false positive and the candidate will have a low score.  Similarly, if a FALSE POSITIVE KOI barely fails a single metric, the score may be near 0.5, indicating that it was deemed a PCin half of the iterations.

To compute the asymmetric sigma values for the Gaussian distribution, we examine the distribution of the robovetter metric for the injected on-target population. We calculate the positive and negative median absolute deviation (MAD) values for each metric as a function of MES and period. These MAD values are then multiplied by a conversion factor of 1.4826 (ADD REF) to put the variability on the same scale as a standard deviation.

NEED TO MENTION AND CLEAN UP FIGURES

NEED TO LIST WHICH METRICS actually GO INTO THE Score CALCULATION

TALK ABOUT SCORE DISTRIBUTION HERE, OR LATER ON IN ANALYSIS?

\begin{figure}
\centering
\includegraphics[width=\linewidth]{Metric-StDev-1.pdf}
\caption{A plot of how we calculated errors for the robovetter score.[NEEDS MORE WORK]}
\label{score-fig-1}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{Scores-1.pdf}
\caption{A plot of how we calculated errors for the robovetter score.}
\label{score-fig-2}
\end{figure}

