\label{s:robovetter}
The dispositioning of the TCEs into the categories of PC and FP is entirely automated and is performed by a piece of code called the Robovetter\footnote{https://github.com/nasa/kepler-robovetter}. This code uses a variety of metrics to evaluate the TCEs and disposition them into PCs and FPs.  

%In this section we describe the different metrics as well as the logic the Robovetter uses to make its decisions. 

Because the TCE population changed significantly between DR24 and DR25 (see Figure~\ref{f:obstces}), the Robovetter had to be improved in order to obtain an acceptable performance.  Also, because we now have simulated false alarms (\invtce\ and \scrtce) and true transits (\injtce), the Robovetter could be tuned to keep the most \injtce{s} (known as completeness) and remove the most \invtce{s} and \scrtce{s} (known as effectiveness). This is change from previous KOI catalogs that prioritized completeness above all else.  In order to sufficiently remove the long period excess of false alarms, this Robovetter introduces new metrics that evaluate individual transits. This expands the work that the code Marshall \citep{Mullally2015c} performed for the DR24 KOI catalog.

Because enough of the Robovetter tests and metrics changed between DR24 and DR25, we describe all of the metrics in full.  However, to not overwhelm the reader, we start by summarizing the important aspects of the Robovetter logic and provide a list of each test's purpose and have moved the details of these metrics to the \S\ref{s:metrics}. We close this section by explaining the creation of a ``disposition score'' that conveys the confidence in the Robovetter's disposition.


\subsection{Summary of the Robovetter}

\noindent In Figure~\ref{robovetter-overview-fig} we present a flowchart that outlines our robotic vetting procedure. Each TCE is subjected to a series of ``yes'' or ``no'' questions (represented by diamonds) that either disposition it into one or more of the four FP categories, or else disposition it as a PC. Behind each question is a series of more specific questions, each answered by quantitative tests. 


\begin{figure*}[ht]
\centering
\includegraphics[width=\linewidth]{RoboVetter-Diagram-V4-Overview.pdf}
\caption{Overview flowchart of the robovetter. Diamonds represent ``yes'' or ``no'' decisions that are made with quantitative metrics. A TCE is dispositioned as a FP if it fails any test (a ``yes'' decision) and is placed in one or more of the FP categories. If a TCE passes all tests (a ``no'' decision for all tests) it is dispositioned as a PC. The section numbers on each component correspond to the sections in this paper where these tests are discussed. ***UPDATE SECTION HEADERS WHEN PAPER IS NEAR FINAL***. More in-depth flowcharts are provided for the not transit-like and significant secondary modules in Figures~\ref{robovetter-transitlike-fig} and \ref{robovetter-sigsec-fig}.}
\label{robovetter-overview-fig}
\end{figure*}


The Robovetter first checks if the TCE corresponds to a secondary eclipse associated with an already examined system. If not, the Robovetter then checks if the TCE is transit-like or not. If it is transit-like, the Robovetter then looks for the presence of a secondary eclipse. In parallel, the Robovetter also looks for evidence of a centroid offset and an ephemeris match to other TCEs and variable stars in the \kepler{} field. 

\label{s:majorflags}
Similar to \citet{Rowe2015a}, \citet{Mullally2015cat}, and \citet{Coughlin2016}, the Robovetter assigns FP TCEs to one or more of the following false positive categories:


\begin{itemize}
  \item Not Transit-Like (NT): a TCE whose light curve is not consistent with that of a transiting planet or eclipsing binary, such as instrumental artifacts and non-eclipsing variable stars.
  \item  Stellar Eclipse (SS): a TCE that is observed to have a significant secondary event, transit shape, or out-of-eclipse variability that indicates the transit-like event is most likely caused by an eclipsing binary. Self-luminous, hot Jupiters with a visible secondary eclipse are also in this category, but are still given a disposition of PC. (In previous KOI catalogs this flag was known as Significant Secondary.)
  \item Centroid Offset (CO): a TCE whose signal is observed to originate on a nearby star, rather than the target star, based on examination of the pixel-level data.
  \item Ephemeris Match Indicates Contamination (EC): a TCE that has the same period and epoch as another object, and is not the true source of the signal given the relative magnitudes, locations, and signal amplitudes of the two objects.
\end{itemize}

The specific tests that caused the TCE to fail that category are given by a minor flag. These flags are described in \S\ref{s:minorflags}) and are available for all FPs.  Table~\ref{t:metrics} gives a summary of the specific tests run by the Robovetter when evaluating a TCE.  The table lists the false positive category the test belongs to and which minor flags it sets.  Note that there are several informative minor flags, which are listed in \S\ref{s:minorflags}, but are not listed in Table~\ref{t:metrics} because they do not cause TCEs to be come FPs.

New to this Robovetter are several tests that look at individual transits. The tests named after the code that calculates a metric and are called: Rubble, Marshall, Chases, Skye, Zuma and Tracker.  Each metric only identifies which transits can be considered ``bad", or not sufficiently transit-like.  The Robovetter then fails the TCE if the number of remaining good transits is not above three, or if the recalculated MES, using only the good transits, drops below 7.1.

Another note-worth change to the DR25 Robovetter is the introduction of the v-shape metric, originally used in \citet{Batalha2013}.  The intent is to remove likely eclipsing binaries which do not show significant secondary eclipses by looking at the shape of the transit, see \S\ref{s:shapemetric}.

\input{table-metrics}

\subsection{Disposition Scores}
\label{s:scores}
We introduce a new feature to this catalog, compared to DR24, called the "Disposition Score". Essentially the disposition score is a value between 0 and 1 that indicates the confidence in a disposition provided by the Robovetter. A higher value indicates more confidence that a TCE is a PC, regardless of the disposition it was given. This feature allows one to select the highest quality PCs by ranking KOIs via the disposition score, for both use in selecting samples for occurrence rate calculations and prioritizing individual objects for follow-up.
%This statistics argument hasn't been proven. We could discuss this, but it belongs in the disucssion "and weight them appropriately for their statistics."

The disposition score was calculated by wrapping the Robovetter in a Monte Carlo routine. In each Monte Carlo iteration, for each TCE, new values are chosen for most of the Robovetter input metrics by drawing from an asymmetric Gaussian distribution centered on the nominal value. The Robovetter then dispositions each TCE given the new values for each metric. The disposition score is simply the fraction of Monte Carlo iterations that result in a disposition of PC. For example, if a TCE that is initially dispositioned as a PC has several metrics that are just barely on the passing side of their Robovetter thresholds, in many iterations at least one will be perturbed across the threshold. As a result, many of the iterations will produce a false positive and the TCE will be dispositioned a PC with a low score.  Similarly, if a TCE that is dispositioned in the nominal run only failed due to a single metric that was barely on the failing side of a threshold, the score may be near 0.5, indicating that it was deemed a PC in half of the iterations.

To compute the asymmetric Gaussian distribution for each metric, we examined the distribution of each metric for the injected on-target planet population on FGK dwarf targets. We calculated a positive and negative median absolute deviation (MAD) value for each metric in a 20 by 20 grid in linear period space (ranging from 0.5 to 500 days) and logarithmic MES space (ranging from 7.1 to 100). Use of the MAD was chosen to be robust to outliers, and MES and period were chosen as they are fundamental properties of a TCE that track each metric's variation well. The MAD values were then multiplied by a conversion factor of 1.4826 to put the variability on the same scale as a Gaussian standard deviation \citep{Hampel1974,Ruppert2010}. A two-dimensional power-law was then fit to the 20 by 20 grid of standard deviation values, separately for the positive and negative sigma directions. With this analytical approximation for a given metric, an asymmetrical Gaussian distribution can be generated for that metric for any TCE given it's MES and period.

An example is shown in Figure~\ref{score-fig-1} for the LPP metric using the DV detrending. The top-left plot shows the LPP values of all on-target injected planets on FGK dwarf targets as a function of period, and the top-right shows them as a function of MES. The middle-left plots shows the measured positive 1$\sigma$ deviation as a function of MES and period, and the middle-right plot shows the resulting best-fit model. The bottom plots show the same thing but for the negative 1$\sigma$ deviation. As can be seen, the scatter in the LPP metric has a weak period dependence, but a strong MES dependence, due to the fact it is easier to measure the overall shape of the light curve (LPP's goal) with higher MES (signal-to-noise). Also seen is that LPP tends to scatter towards higher values much more than lower values.

Most, but not all, of the Robovetter metrics were amenable to this approach. Specifically, the list of metrics that perturbed in the manner above to generate the score values were: LPP for both DV and ALT, all the Modelshift metrics for both DV and ALT, the all-transits CHASES value, the max SES to MES value, the depth- and Robovetter-based odd/even metrics for DV and ALT, the ghost diagnostic, and the recomputed MES using only `good' transits left after the individual transit metrics.

\begin{figure*}
\centering
\begin{tabular}{cc}
\includegraphics[width=0.5\linewidth]{ScoreFig-1.png} &
\includegraphics[width=0.5\linewidth]{ScoreFig-2.png} \\
\includegraphics[width=0.5\linewidth]{ScoreFig-3.png} &
\includegraphics[width=0.5\linewidth]{ScoreFig-4.png} \\
\includegraphics[width=0.5\linewidth]{ScoreFig-5.png} &
\includegraphics[width=0.5\linewidth]{ScoreFig-6.png}
\end{tabular}
\caption{The top-left plot shows the LPP values of all on-target injected planets on FGK dwarf targets as a function of period, and the top-right shows them as a function of MES. The middle-left plots shows the measured positive 1$\sigma$ deviation as a function of MES and period, and the middle-right plot shows the resulting best-fit model. The bottom plots show the same thing but for the negative 1$\sigma$ deviation. These resulting model distributions are used when computing the Robovetter disposition score.}
\label{score-fig-1}
\end{figure*}
