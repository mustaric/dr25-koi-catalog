\label{s:robovetter}
The dispositioning of the TCEs into the categories of PC and FP is entirely automated and is performed by the Robovetter\footnote{\label{rvgithub}\url{https://github.com/nasa/kepler-robovetter}}. This code uses a variety of metrics to evaluate the TCEs and disposition them into PCs and FPs.  

%In this section we describe the different metrics as well as the logic the Robovetter uses to make its decisions. 

Because the TCE population changed significantly between DR24 and DR25 (see Figure~\ref{f:obstces}), the Robovetter had to be improved in order to obtain acceptable performance.  Also, because we now have simulated false alarms (\invtces\ and \scrtces) and true transits (\injtces), the Robovetter could be tuned to keep the most \injtce{s} and remove the most \invtce{s} and \scrtce{s}. This is a significant change from previous KOI catalogs that prioritized completeness above all else.  In order to sufficiently remove the long period excess of false alarms, this Robovetter introduces new metrics that evaluate individual transits (in addition to the phase-folded transits), expanding the work that the code Marshall \citep{Mullally2016} performed for the DR24 KOI catalog.

Because most of the Robovetter tests and metrics changed between DR24 and DR25, we fully describe all of the metrics.  In this section we summarize the important aspects of the Robovetter logic and only provide a list of each test's purpose. The details of these metrics, and more details on the Robovetter logic, can be found in Appendix~\ref{s:metrics}. We close this section by explaining the creation of the ``disposition score'', a number which conveys the confidence in the Robovetter's disposition.

\subsection{Summary of the Robovetter}

In Figure~\ref{robovetter-overview-fig} we present a flowchart that outlines our robotic vetting procedure. Each TCE is subjected to a series of ``yes'' or ``no'' questions (represented by diamonds) that either disposition it into one or more of the four FP categories, or else disposition it as a PC. Behind each question is a series of more specific questions, each answered by quantitative tests. 


\begin{figure*}[htb]
\centering
\includegraphics[width=\linewidth]{RoboVetter-Diagram-V4-Overview.pdf}
\caption{Overview flowchart of the Robovetter. Diamonds represent ``yes'' or ``no'' decisions that are made with quantitative metrics. A TCE is dispositioned as a FP if it fails any test (a ``yes'' decision) and is placed in one or more of the FP categories. (A TCE that is identified as being the secondary eclipse of a system is placed in both the `Not Transit-Like' and 'Stellar Eclipse' categories.) If a TCE passes all tests (a ``no'' decision for all tests) it is dispositioned as a PC. The section numbers on each component correspond to the sections in this paper where these tests are discussed. More in-depth flowcharts are provided for the not transit-like and significant secondary modules in Figures~\ref{robovetter-transitlike-fig} and \ref{robovetter-sigsec-fig}.}
\label{robovetter-overview-fig}
\end{figure*}


First, if the TCE under investigation is not the first in the system, the Robovetter checks if the TCE corresponds to a secondary eclipse associated with an already examined TCE in that system. If not, the Robovetter then checks if the TCE is transit-like. If it is transit-like, the Robovetter then looks for the presence of a secondary eclipse. In parallel, the Robovetter looks for evidence of a centroid offset, as well as an ephemeris match to other TCEs and variable stars in the \kepler{} field. 

\label{s:majorflags}
Similar to previous KOI catalogs \citep{Coughlin2016, Mullally2015cat, Rowe2015cat}, the Robovetter assigns FP TCEs to one or more of the following false positive categories:


\begin{itemize}
  \item Not Transit-Like (NT): a TCE whose light curve is not consistent with that of a transiting planet or eclipsing binary. These TCEs are usually caused by instrumental artifacts or non-eclipsing variable stars. If the Robovetter worked perfectly, all false alarms, as we have defined them in this paper, would be marked as FPs with only this Not Transit-Like flag set. 
  \item  Stellar Eclipse (SS): a TCE that is observed to have a significant secondary event, v-shaped transit profile, or out-of-eclipse variability that indicates the transit-like event is very likely caused by an eclipsing binary. Self-luminous, hot Jupiters with a visible secondary eclipse are also in this category, but are still given a disposition of PC. (In previous KOI catalogs this flag was known as Significant Secondary.)
  \item Centroid Offset (CO): a TCE whose signal is observed to originate from a source other than the target star, based on examination of the pixel-level data.
  \item Ephemeris Match Indicates Contamination (EC): a TCE that has the same period and epoch as another object, and is not the true source of the signal given the relative magnitudes, locations, and signal amplitudes of the two objects. See \citet{Coughlin2014}.
\end{itemize}

The specific tests that caused the TCE to fail are specified by minor flags. These flags are described in Appendix~\ref{s:minorflags} and are available for all FPs.  Table~\ref{t:metrics} gives a summary of the specific tests run by the Robovetter when evaluating a TCE.  The table lists the false positive category (NT, SS, CO or EC) of the test and also which minor flags are set by that test.  Note that there are several informative minor flags, which are listed in Appendix~\ref{s:minorflags}, but are not listed in Table~\ref{t:metrics} because they do not change the disposition of a TCE. Also, Appendix~\ref{s:minorflags} tabulates how often each minor flag was set to help understand the frequency of each type of FP. 

New to this Robovetter are several tests that look at individual transits. The tests are named after the code that calculates the relevant metric and are called: Rubble, Marshall, Chases, Skye, Zuma, and Tracker.  Each metric only identifies which transits can be considered "bad", or not sufficiently transit-like.  The Robovetter only fails the TCE if the number of remaining good transits is less than three, or if the recalculated MES, using only the good transits, drops below 7.1.

Another noteworthy update to the Robovetter in DR25 is the introduction of the v-shape metric, originally used in \citet{Batalha2013}.  The intent is to remove likely eclipsing binaries which do not show significant secondary eclipses by looking at the shape and depth of the transit (see \S\ref{s:shapemetric}).

% Big table of all the input metrics
\input{table-metrics}


\subsection{Disposition Scores}
\label{s:scores}
We introduce a new feature to this catalog called the Disposition Score. Essentially the disposition score is a value between 0 and 1 that indicates the confidence in a disposition provided by the Robovetter. A higher value indicates more confidence that a TCE is a PC, regardless of the disposition it was given. This feature allows one to select the highest quality PCs by ranking KOIs via the disposition score, for both use in selecting samples for occurrence rate calculations and prioritizing individual objects for follow-up. \emph{We stress that the disposition score does not map directly to a probability that the signal is a planet.} However, in \S\ref{s:crscores} we discuss how the disposition score can be used to adjust the reliability of a sample.
%This statistics argument hasn't been proven. We could discuss this, but it belongs in the disucssion "and weight them appropriately for their statistics."

The disposition score was calculated by wrapping the Robovetter in a Monte Carlo routine. In each Monte Carlo iteration, for each TCE, new values are chosen for most of the Robovetter input metrics by drawing from an asymmetric Gaussian distribution centered on the nominal value. The Robovetter then dispositions each TCE given the new values for its metrics. The disposition score is simply the fraction of Monte Carlo iterations that result in a disposition of PC. (We used 10,000 iterations for the results in this catalog.) For example, if a TCE that is initially dispositioned as a PC has several metrics that are just barely on the passing side of their Robovetter thresholds, in many iterations at least one will be perturbed across the threshold. As a result, many of the iterations will produce a false positive and the TCE will be dispositioned as a PC with a low score.  Similarly, if a TCE only fails due to a single metric that was barely on the failing side of a threshold, the score may be near 0.5, indicating that it was deemed a PC in half of the iterations.  Since a TCE is deemed a FP even if only one metric fails, nearly all FPs have scores less than 0.5, with most very close to 0.0.  PCs have a wider distribution of scores from 0.0 to 1.0 depending on how many of their metrics fall near to the various Robovetter thresholds.

To compute the asymmetric Gaussian distribution for each metric, we examined the metric distributions for the injected on-target planet population on FGK dwarf targets. We calculated a positive and negative median absolute deviation (MAD) value for each metric in a 20 by 20 grid in linear period space (ranging from 0.5 to 500 days) and logarithmic MES space (ranging from 7.1 to 100). We chose to use MAD because it is robust to outliers. MES and period were chosen as they are fundamental properties of a TCE that well characterize each metric's variation. The MAD values were then multiplied by a conversion factor of 1.4826 to put the variability on the same scale as a Gaussian standard deviation \citep{Hampel1974,Ruppert2010}. A two-dimensional power-law was then fitted to the 20 by 20 grid of standard deviation values, separately for the positive and negative sigma directions. With this analytical approximation for a given metric, an asymmetric Gaussian distribution can be generated for each metric for any TCE given its MES and period.

An example is shown in Figure~\ref{score-fig-1} for the LPP metric (Locality Preserving Projections, see \S\ref{s:lpp}) using the DV detrending. The top-left plot shows the LPP values of all on-target injected planets on FGK dwarf targets as a function of period, and the top-right shows them as a function of MES. The middle-left plot shows the measured positive 1$\sigma$ deviation (in the same units as the LPP metric) as a function of MES and period, and the middle-right plot shows the resulting best-fit model. The bottom plots show the same thing but for the negative 1$\sigma$ deviation. As can be seen, the scatter in the LPP metric has a weak period dependence, but a strong MES dependence, due to the fact it is easier to measure the overall shape of the light curve (LPP's goal) with higher MES (signal-to-noise). 
%Also seen is that LPP is bounded by zero on one side and can scatter to very high values, especially for low MES events. 

Most, but not all, of the Robovetter metrics were amenable to this approach. Specifically, the list of metrics that were perturbed in the manner above to generate the score values were: LPP (both DV and ALT), all the Model-shift metrics (MS$_1$,MS$_2$,MS$_3$, and MS Secondary, both DV and ALT), TCE Chases, max-SES-to-MES, the two odd/even metrics (both DV and ALT), Ghost Diagnostic, and the recomputed MES using only good transits left after the individual transit metrics.

\begin{figure*}[hp]
\centering
\begin{tabular}{cc}
\includegraphics[width=0.485\linewidth]{ScoreFig-1.pdf} &
\includegraphics[width=0.485\linewidth]{ScoreFig-2.pdf} \\
\includegraphics[width=0.485\linewidth]{ScoreFig-3.pdf} &
\includegraphics[width=0.485\linewidth]{ScoreFig-4.pdf} \\
\includegraphics[width=0.485\linewidth]{ScoreFig-5.pdf} &
\includegraphics[width=0.485\linewidth]{ScoreFig-6.pdf}
\end{tabular}
\caption{The top-left plot shows the LPP$_{DV}$ values of all on-target injected planets on FGK dwarf targets as a function of period, and the top-right shows them as a function of MES. The middle-left plots shows the measured positive 1$\sigma$ deviation (in the same units as LPP$_{DV}$) as a function of MES and period, and the middle-right plot shows the resulting best-fit model. The bottom plots show the same thing, but for the negative 1$\sigma$ deviation (again in the same units as LPP$_{DV}$). These resulting model distributions are used when computing the Robovetter disposition score.}
\label{score-fig-1}
\end{figure*}
